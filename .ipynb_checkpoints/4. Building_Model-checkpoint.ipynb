{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and create a column `Year` to help increase a feature for training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a column `Year` - distance from First Registration's Year of the car to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"data\\cleaned_data_edited.csv\",index_col=\"ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi cột 'Year' thành int\n",
    "data['Year'] = data['First registration'].str[-4:].astype(int)\n",
    "data['Year'] = 2024 - data['Year']\n",
    "\n",
    "# Kiểm tra kiểu dữ liệu của cột 'Year'\n",
    "print(data['Year'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find object columns and low cardinality columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to our data have many categorical columns, we have to do one hot encoding for training model. Before handling one-hot, we have to:\n",
    "- Find categorical (object) columns.\n",
    "- Find columns that have low cardinality.\n",
    "\n",
    "Why have to find columns that have low cardinality?\n",
    "- For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['CARNAME', 'Make', 'Model', 'Body color', 'Interior color', 'Interior material', 'Body', 'Doors', 'Fuel', 'Transmission', 'Drive type', 'Emission class', 'First registration', 'Condition', 'Tags']\n",
      "Low cardinality col:\n",
      "['Interior color', 'Interior material', 'Doors', 'Fuel', 'Transmission', 'Drive type', 'Emission class', 'Condition']\n"
     ]
    }
   ],
   "source": [
    "s = (data.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)\n",
    "\n",
    "low_cardinality_cols = [col for col in object_cols if data[col].nunique() < 10]\n",
    "# low_cardinality_cols.append(\"Make\")\n",
    "print(\"Low cardinality col:\")\n",
    "print (low_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Due to the column `Tags` is a multiple value column, we have to choose which tag (special function) to do one hot encoding and put to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Air suspension', 'Digital cockpit', 'Electric adjustable front seats',\n",
       "       'Ventilated front seats'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_df =  data[[\"Price(EUR)\",\"Tags\"]].copy()\n",
    "\n",
    "# Get each tag in each multiple value row\n",
    "tags = one_hot_df['Tags'].str.split('; ', expand=True)\n",
    "\n",
    "# Stack to make the DataFrame long, then get_dummies and group by index before summing\n",
    "get_dummy = pd.get_dummies(tags.stack()).groupby(level=0).sum()\n",
    "\n",
    "# Join the one-hot encoded DataFrame back to the original DataFrame\n",
    "one_hot_df = one_hot_df.join(get_dummy)\n",
    "\n",
    "# Drop the `Tags` because we dont need it anymore\n",
    "one_hot_df = one_hot_df.drop(\"Tags\",axis=1)\n",
    "\n",
    "# Calculate correlation with 'Price(EUR)'\n",
    "correlation = one_hot_df.corr()['Price(EUR)']\n",
    "\n",
    "# Get the top 10 tags with highest correlation with 'Price(EUR)'\n",
    "# top_10_corr_tags = correlation.nlargest(9).index\n",
    "#Lấy ra top tags có tương quan > 0.25\n",
    "top_10_corr_tags = correlation[correlation >= 0.25].index\n",
    "\n",
    "# Select only the top 10 tags with highest correlation with 'Price(EUR)'\n",
    "one_hot_df = one_hot_df[top_10_corr_tags].drop([\"Price(EUR)\"],axis=1)\n",
    "\n",
    "one_hot_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find top 8  Car Manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ferrari', 'Lamborghini', 'Rolls-Royce', 'Others'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(data['Make'])\n",
    "data_encoded = data[['Price(EUR)']].join(one_hot) \n",
    "correlation = data_encoded.corr()['Price(EUR)']\n",
    "\n",
    "#LẤy ra top 10 make có tương quan cao nhất > 0.25\n",
    "top_10_Make = correlation[correlation >= 0.25].index\n",
    "#top_10_Make = correlation.nlargest(11).index\n",
    "top_10_Make = top_10_Make.drop(\"Price(EUR)\")\n",
    "\n",
    "one_hot = one_hot[top_10_Make]\n",
    "one_hot['Others'] = (one_hot.sum(axis=1) == 0)\n",
    "one_hot.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ferrari</th>\n",
       "      <th>Lamborghini</th>\n",
       "      <th>Rolls-Royce</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61032325</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61032250</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61032203</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61032104</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61032099</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ferrari  Lamborghini  Rolls-Royce  Others\n",
       "ID                                                 \n",
       "61032325    False        False        False    True\n",
       "61032250    False        False        False    True\n",
       "61032203    False        False        False    True\n",
       "61032104    False        False        False    True\n",
       "61032099    False        False        False    True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To train and test a model:\n",
    "    - First we will split our data into X_train, X_valid, y_train, y_valid dataset.\n",
    "    - Second, we have to handle categorical features - one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in data.columns if \n",
    "                data[cname].dtype in ['int64', 'float64', 'int32']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "\n",
    "X = data[my_cols].copy().reset_index(drop=True)\n",
    "one_hot_df = one_hot_df.reset_index(drop=True)\n",
    "one_hot = one_hot.reset_index(drop=True)\n",
    "\n",
    "X = pd.concat([X, one_hot_df, one_hot], axis=1)\n",
    "\n",
    "y = X[\"Price(EUR)\"].copy()\n",
    "X.drop([\"Price(EUR)\"], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seats',\n",
       " 'Power(kW)',\n",
       " 'CO2 emissions(g/km)',\n",
       " 'Mileage(km)',\n",
       " 'Consumption(l/100km or kWh/100km)',\n",
       " 'Price(EUR)',\n",
       " 'Engine capacity(ccm)',\n",
       " 'Previous owners',\n",
       " 'Year']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2289 entries, 0 to 2288\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Interior color                     2289 non-null   object \n",
      " 1   Interior material                  2289 non-null   object \n",
      " 2   Doors                              2289 non-null   object \n",
      " 3   Fuel                               2289 non-null   object \n",
      " 4   Transmission                       2289 non-null   object \n",
      " 5   Drive type                         2289 non-null   object \n",
      " 6   Emission class                     2289 non-null   object \n",
      " 7   Condition                          2289 non-null   object \n",
      " 8   Seats                              2289 non-null   float64\n",
      " 9   Power(kW)                          2289 non-null   int64  \n",
      " 10  CO2 emissions(g/km)                2289 non-null   int64  \n",
      " 11  Mileage(km)                        2289 non-null   int64  \n",
      " 12  Consumption(l/100km or kWh/100km)  2289 non-null   float64\n",
      " 13  Engine capacity(ccm)               2289 non-null   float64\n",
      " 14  Previous owners                    2289 non-null   float64\n",
      " 15  Year                               2289 non-null   int32  \n",
      " 16  Air suspension                     2289 non-null   int64  \n",
      " 17  Digital cockpit                    2289 non-null   int64  \n",
      " 18  Electric adjustable front seats    2289 non-null   int64  \n",
      " 19  Ventilated front seats             2289 non-null   int64  \n",
      " 20  Ferrari                            2289 non-null   bool   \n",
      " 21  Lamborghini                        2289 non-null   bool   \n",
      " 22  Rolls-Royce                        2289 non-null   bool   \n",
      " 23  Others                             2289 non-null   bool   \n",
      "dtypes: bool(4), float64(4), int32(1), int64(7), object(8)\n",
      "memory usage: 357.8+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PipeLine for Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we have to define transformer for the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because numerical col in our data were preprocess already, so we just have to preprocess for categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, low_cardinality_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second: Fit model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 12115.062222874305\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', RandomForestRegressor(n_estimators=30,\n",
    "                                                              random_state=0))\n",
    "                             ])\n",
    "\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scores:\n",
      " [17436.06234989 12265.0669923  12092.84526433 11673.96573921\n",
      " 10977.8855873   9771.34508089 11539.47008064 10928.33916883\n",
      " 10413.61166176 11560.56315619]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=10,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Interior color', 'Interior material', 'Doors', 'Fuel', 'Transmission',\n",
       "       'Drive type', 'Emission class', 'Condition', 'Seats', 'Power(kW)',\n",
       "       'CO2 emissions(g/km)', 'Mileage(km)',\n",
       "       'Consumption(l/100km or kWh/100km)', 'Engine capacity(ccm)',\n",
       "       'Previous owners', 'Year', 'Air suspension', 'Digital cockpit',\n",
       "       'Electric adjustable front seats', 'Ventilated front seats', 'Ferrari',\n",
       "       'Lamborghini', 'Rolls-Royce', 'Others'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model, Test and make Prediction from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# # function for comparing different approaches\n",
    "# def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "#     model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_valid)\n",
    "#     return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "# print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))\n",
    "def input_car_info():\n",
    "    # Initialize an empty dictionary to hold user input\n",
    "    car_info = {}\n",
    "\n",
    "    # List all the features\n",
    "    features = ['Interior color', 'Interior material', 'Doors', 'Fuel', 'Transmission', \n",
    "                'Drive type', 'Emission class', 'Condition', 'Seats', 'Power(kW)', \n",
    "                'CO2 emissions(g/km)', 'Mileage(km)', 'Consumption(l/100km or kWh/100km)', \n",
    "                'Engine capacity(ccm)', 'Previous owners', 'Air suspension', \n",
    "                'Ventilated front seats', 'Electric adjustable front seats', \n",
    "                'Digital cockpit', 'Burmester audio', 'Heated rear seats', \n",
    "                'Laser headlights', 'Adaptive cruise control']\n",
    "\n",
    "    # Ask the user to input values for each feature\n",
    "    for feature in features:\n",
    "        value = input(f\"Please enter the {feature} of the car: \")\n",
    "        car_info[feature] = [value]  # Use a list here because pd.DataFrame expects a list\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    X_input = pd.DataFrame(car_info)\n",
    "\n",
    "    return X_input\n",
    "\n",
    "# Call the function to get user input and create X_input\n",
    "#X_input = input_car_info()\n",
    "# X_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = my_pipeline.predict(X_input)\n",
    "# preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dumped!\n"
     ]
    }
   ],
   "source": [
    "#Lưu model lại với file model.pkl\n",
    "import joblib\n",
    "joblib.dump(my_pipeline, 'deploy/model.pkl')\n",
    "print(\"Model dumped!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
